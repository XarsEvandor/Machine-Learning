{"cells":[{"cell_type":"markdown","metadata":{"id":"KUGvmm_yn1uo"},"source":["# 9 Training a Deep Convolutional Autoencoder (DCA) on MNIST\n","This example illustrates a DCA architecture in Tensorflow/Keras. It learn on the MNIST dataset to reconstruct 28x28 grayscale images. It uses the **ADAM** optimizer to minimize an **MSE** reconstruction error.\n","\n","Except the usual convolutional and max pooling layer it has the **Deconvolutional** layers. The code is the activation of the neurons that belong to a fully-connected (dense) layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2taBUomqJHh"},"outputs":[],"source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/9. Autoencoders\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1uCq93lnzWS"},"outputs":[],"source":["import os\n","import csv\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from mllib.utils import RandomSeed\n","from clang.cindex import callbacks\n","from mllib.visualization import CPlot\n","# __________ | Settings | __________\n","IS_PLOTING_DATA         = False\n","IS_DEBUGABLE            = True\n","IS_RETRAINING           = True\n","RandomSeed(2022)"]},{"cell_type":"markdown","source":["# Hyperparameters\n","For each training experiment, we have the encode and the decoder features for the corresponding convolutional and deconvolutional layers. We also have downsampling and upsampling inside the architecture the bottleneck code layer has way less dimensions than its input activation tensor."],"metadata":{"id":"5z0Jm3SFxJWv"}},{"cell_type":"code","source":["# __________ | Hyperparameters | __________\n","CONFIG_DA1 = {\n","                 \"ModelName\": \"MNIST_DA1\"\n","                ,\"DA.InputShape\": [28,28,1]\n","                ,\"DA.EncoderFeatures\": [64,64]\n","                ,\"DA.CodeDimensions\" : 32\n","                ,\"DA.Downsampling\"   : [True,True]\n","                ,\"DA.DecoderFeatures\": [64,64,1]\n","                ,\"DA.DecoderInputResolution\": [7,7]\n","                ,\"DA.UpSampling\"     :  [True,True]\n","                ,\"DA.HasBatchNormalization\": True\n","                ,\"Training.MaxEpoch\": 20\n","                ,\"Training.BatchSize\": 500\n","                ,\"Training.LearningRate\": 1e-3\n","            }\n","\n","CONFIG_DA2 = {\n","                 \"ModelName\": \"MNIST_DA2\"\n","                ,\"DA.InputShape\": [28,28,1]\n","                ,\"DA.EncoderFeatures\": [32,32,32,32]\n","                ,\"DA.CodeDimensions\" : 20\n","                ,\"DA.Downsampling\"   : [True,False,True,False]\n","                ,\"DA.DecoderFeatures\": [32,32,32,32,1]\n","                ,\"DA.DecoderInputResolution\": [7,7]\n","                ,\"DA.UpSampling\"     :  [False,True,False,True]\n","                ,\"DA.HasBatchNormalization\": True\n","                ,\"Training.MaxEpoch\": 20\n","                ,\"Training.BatchSize\": 500\n","                ,\"Training.LearningRate\": 1e-3\n","            }\n","                \n","CONFIG = CONFIG_DA1"],"metadata":{"id":"-fGhVtyRneUP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MNIST\n","This [MNIST dataset](http://yann.lecun.com/exdb/mnist/) dataset, that dates back to 1998, has become a standard toy dataset to understand the image classification task. It contains 70000 grayscale images of 28x28 dimensions for the handwritten digits 0,1,..9. \n","It is already splitted into a training set of 60000 images, while the rest 10000 are used to validate the model\n","\n","# Dataset loading and previewing\n","We are reusing an existing dataset in Tensorflow format. We load the data and extract them as numpy arrays to view some images, and later use the target class labels for evaluation."],"metadata":{"id":"Cc5voM78xgaC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiDspBvJoHOZ"},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","\n","(oTSData, oVSData), oDataSetInfo = tfds.load(\n","    'mnist',\n","    split=['train', 'test'],\n","    shuffle_files=True,\n","    as_supervised=True,\n","    with_info=True,\n",")\n","  \n","# Takes one minibatch out of the dataset. Here the size of the minibatch is the total count of samples\n","for tImages, tLabels in oVSData.batch(oDataSetInfo.splits['test'].num_examples).take(1):\n","    nImages            = tImages.numpy()\n","    nTargetClassLabels = tLabels.numpy()  \n","\n","print(\"VS image features tensor shape:\" , nImages.shape)\n","print(\"VS image targets vector shape :\", nTargetClassLabels.shape)\n","\n","if IS_PLOTING_DATA:\n","    for nIndex, nSample in enumerate(nImages):\n","      nLabel = nTargetClassLabels[nIndex]\n","      if (nIndex >= 0 and nIndex <= 20):\n","           \n","        if nIndex == 0:\n","            print(\"Image sample shape            :\", nSample.shape)\n","        nImage =  nSample.astype(np.uint8) \n","        plt.imshow(nImage[:,:,0], cmap=\"gray\") #https://matplotlib.org/stable/tutorials/colors/colormaps.html\n","        #plt.imshow(nImage[4:22, 0:15, :], cmap=\"gray\") #https://matplotlib.org/stable/tutorials/colors/colormaps.html\n","        plt.title(\"Digit %d\" % nLabel)\n","        plt.show()    "]},{"cell_type":"markdown","source":["# Data Feeding for Training and Validation"],"metadata":{"id":"VPyYbsBWY-nb"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------------\n","def NormalizeImage(p_tImage, p_tLabel):\n","    # Normalizes color component values from `uint8` to `float32`.\n","    tNormalizedImage = tf.cast(p_tImage, tf.float32) / 255.\n","    # Target class labels into one-hot encoding\n","    tTargetImage = tNormalizedImage \n","    \n","    return tNormalizedImage, tTargetImage\n","# -----------------------------------------------------------------------------------\n","\n","nBatchSize = CONFIG[\"Training.BatchSize\"]\n","\n","# Training data feed pipeline\n","oTSData = oTSData.map(NormalizeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","oTSData = oTSData.cache()\n","oTSData = oTSData.shuffle(oDataSetInfo.splits['train'].num_examples)\n","oTSData = oTSData.batch(nBatchSize)\n","oTSData = oTSData.prefetch(tf.data.AUTOTUNE)\n","print(\"Training data feed object:\", oTSData)\n","\n","# Validation data feed pipeline\n","oVSData = oVSData.map(NormalizeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","oVSData = oVSData.batch(oDataSetInfo.splits['test'].num_examples)\n","print(\"Validation data feed object:\", oVSData)"],"metadata":{"id":"fSWlxinCY9lG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Custom Convolutional Autoencoder Architecture\n","After several convolutional layers we have a rank-3 activation tensor e.g. 7x7x64. We flatten this tensor to be used as input to our dense code layer. The output of this dense layer is fed input another dense layer that is the first part of the decoder and has 7*7*64 features. We reshape it to a rank-3 tensor that is fed to the first deconvolution operation.\n"],"metadata":{"id":"P_tiMbyzc1jV"}},{"cell_type":"code","source":["\n","# __________ // Create the Machine Learning model and training algorithm objects \\\\ __________\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import regularizers\n","from mllib.helpers import CKerasModelStructure, CModelConfig\n","\n","# =========================================================================================================================\n","class CConvolutionalAutoencoder(keras.Model):\n","    # --------------------------------------------------------------------------------------\n","    # Constructor\n","    def __init__(self, p_oConfig):\n","        super(CConvolutionalAutoencoder, self).__init__()\n","        \n","        # ..................... Object Attributes ...........................\n","        self.Config = CModelConfig(self, p_oConfig)\n","        \n","        \n","        self.EncoderFeatures    = self.Config.Value[\"DA.EncoderFeatures\"]\n","        self.DecoderFeatures    = self.Config.Value[\"DA.DecoderFeatures\"]\n","        self.Downsampling       = self.Config.Value[\"DA.Downsampling\"]\n","        self.Upsampling         = self.Config.Value[\"DA.UpSampling\"]\n","        self.Structure = None \n","        \n","        # ......... Keras layers .........\n","        self.CodeFlatteningLayer = None\n","        self.CodeDenseLayer      = None\n","        self.KerasLayers         = []\n","        # ...................................................................\n","        \n","        self.Config.DefaultValue(\"DA.ActivationFunction\", \"relu\")\n","        self.Config.DefaultValue(\"DA.ConvHasBias\", False)\n","        self.Config.DefaultValue(\"DA.HasBatchNormalization\", False)\n","        self.Config.DefaultValue(\"DA.KernelInitializer\", \"glorot_uniform\")\n","        self.Config.DefaultValue(\"DA.BiasInitializer\", \"zeros\")\n","        self.Config.DefaultValue(\"Training.RegularizeL2\", False)\n","        self.Config.DefaultValue(\"Training.WeightDecay\", 1e-5)\n","            \n","        if self.Config.Value[\"Training.RegularizeL2\"]:\n","            print(\"Using L2 regularization of weights with weight decay %.6f\" % self.Config[\"Training.WeightDecay\"])\n","              \n","        self.Create()\n","    # --------------------------------------------------------------------------------------------------------\n","    def createWeightRegulizer(self):\n","        if self.Config.Value[\"Training.RegularizeL2\"]:\n","            oWeightRegularizer = regularizers.L2(self.Config.Value[\"Training.WeightDecay\"])\n","        else:\n","            oWeightRegularizer = None\n","        return oWeightRegularizer          \n","    # --------------------------------------------------------------------------------------\n","    def Create(self):\n","        for nIndex,nFeatures in enumerate(self.EncoderFeatures):\n","            nStride = 1\n","            if self.Downsampling[nIndex]:\n","                nStride = 2\n","            oConvolution = layers.Conv2D(nFeatures, kernel_size=(3,3), strides=nStride, padding=\"same\"\n","                                  , use_bias=self.Config.Value[\"DA.ConvHasBias\"]\n","                                  , kernel_initializer=self.Config.Value[\"DA.KernelInitializer\"]\n","                                  , bias_initializer=self.Config.Value[\"DA.BiasInitializer\"]\n","                                  , kernel_regularizer=self.createWeightRegulizer()                            \n","                                  )\n","            self.KerasLayers.append(oConvolution)\n","              \n","            oActivation  = layers.Activation(self.Config.Value[\"DA.ActivationFunction\"])\n","            self.KerasLayers.append(oActivation)\n","            \n","            if self.Config.Value[\"DA.HasBatchNormalization\"]:\n","                oNormalization = layers.BatchNormalization()\n","                self.KerasLayers.append(oNormalization)\n","\n","        #https://github.com/Seratna/TensorFlow-Convolutional-AutoEncoder\n","        self.CodeFlatteningLayer = layers.Flatten()\n","        self.KerasLayers.append(self.CodeFlatteningLayer)\n","        \n","        self.CodeDenseLayer      = layers.Dense(self.Config.Value[\"DA.CodeDimensions\"], activation=\"relu\")\n","        self.KerasLayers.append(self.CodeDenseLayer)\n","        \n","        \n","        nDecoderInputResolution = self.Config.Value[\"DA.DecoderInputResolution\"]\n","        oDecoderFirstLayer = layers.Dense(nDecoderInputResolution[0]*nDecoderInputResolution[1]*self.DecoderFeatures[0], activation=\"relu\")\n","        self.KerasLayers.append(oDecoderFirstLayer)\n","        \n","        oReshape = layers.Reshape([nDecoderInputResolution[0],nDecoderInputResolution[1],self.DecoderFeatures[0]])\n","        self.KerasLayers.append(oReshape)\n","                                \n","           \n","        for nIndex,nFeatures in enumerate(self.DecoderFeatures[1:]):\n","            nStride = 1\n","            if self.Upsampling[nIndex]:\n","                nStride = 2\n","            oDeconvolution = layers.Conv2DTranspose( nFeatures, kernel_size=(3,3), strides=nStride, padding=\"same\"\n","                                              , use_bias=self.Config.Value[\"DA.ConvHasBias\"]\n","                                              , kernel_initializer=self.Config.Value[\"DA.KernelInitializer\"]\n","                                              , bias_initializer=self.Config.Value[\"DA.BiasInitializer\"]\n","                                              , kernel_regularizer=self.createWeightRegulizer()                            \n","                                              )\n","            self.KerasLayers.append(oDeconvolution)\n","              \n","            oActivation  = layers.Activation(self.Config.Value[\"DA.ActivationFunction\"])\n","            self.KerasLayers.append(oActivation)\n","            \n","            if self.Config.Value[\"DA.HasBatchNormalization\"]:\n","                oNormalization = layers.BatchNormalization()\n","                self.KerasLayers.append(oNormalization)\n","                \n","        oLastLayerActivation = layers.Activation(\"sigmoid\")\n","        self.KerasLayers.append(oLastLayerActivation)\n","        \n","    # --------------------------------------------------------------------------------------------------------\n","    def call(self, p_tInput):\n","        bPrint = self.Structure is None\n","        if bPrint:\n","            self.Structure = CKerasModelStructure()\n","          \n","        self.Input = p_tInput\n","        \n","        # ....... Convolutional Feature Extraction  .......\n","        # Feed forward to the next layer\n","        tA = p_tInput\n","        if bPrint:\n","            self.Structure.Add(tA) \n","        \n","        for nIndex,oKerasLayer in enumerate(self.KerasLayers):\n","            if bPrint:\n","                self.Structure.Add(tA)         \n","            tA = oKerasLayer(tA)\n","        \n","        return tA\n","    # --------------------------------------------------------------------------------------------------------\n","# =========================================================================================================================\n"],"metadata":{"id":"m1klKxV_c17N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create the Autoencoder neural network model and training algorithm objects\n","**Deep Learning techniques**\n"],"metadata":{"id":"DhT1bvZudWDr"}},{"cell_type":"code","source":["oNN = CConvolutionalAutoencoder(CONFIG)\n","\n","# -----------------------------------------------------------------------------------\n","def LRSchedule(epoch, lr):\n","    nNewLR = lr\n","    for nIndex,oSchedule in enumerate(CONFIG[\"Training.LearningRateScheduling\"]):\n","        if epoch == oSchedule[0]:\n","            nNewLR = oSchedule[1]\n","            print(\"Schedule #%d: Setting LR to %.5f\" % (nIndex+1,nNewLR))\n","            break\n","    return nNewLR\n","# -----------------------------------------------------------------------------------   \n","\n","nInitialLearningRate    = CONFIG[\"Training.LearningRate\"]  \n","  \n","oCostFunction   = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n","oOptimizer = tf.keras.optimizers.Adam(nInitialLearningRate)\n","oCallbacks = None"],"metadata":{"id":"Lw53Davlln-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Inspect the model architecture"],"metadata":{"id":"-sq6PkuMHRyM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6PQlq3KEoFVB"},"outputs":[],"source":["# Compile the model for training\n","sModelFolderName = CONFIG[\"ModelName\"]\n","        \n","bIsCompiledForTraining = False\n","if not os.path.isdir(sModelFolderName) or IS_RETRAINING:\n","    oNN.compile(loss=oCostFunction, optimizer=oOptimizer, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","    oNN.predict(oVSData)\n","    oNN.Structure.Print(\"Model-Structure-%s.csv\" % CONFIG[\"ModelName\"])\n","    bIsCompiledForTraining = True"]},{"cell_type":"markdown","metadata":{"id":"JUmXdT2coFHN"},"source":["### Train and evalute the model"]},{"cell_type":"code","source":["if bIsCompiledForTraining:\n","    # Train the model\n","    if IS_DEBUGABLE:\n","        oNN.run_eagerly = True\n","        \n","    oProcessLog = oNN.fit(  oTSData, batch_size=nBatchSize\n","                            ,epochs=CONFIG[\"Training.MaxEpoch\"]\n","                            ,validation_data=oVSData\n","                            ,callbacks=oCallbacks\n","                          )\n","    oNN.summary()          \n","    oNN.save(sModelFolderName)      \n","else:\n","    # The model is trained and its state is saved (all the trainable parameters are saved). We load the model to recall the samples \n","    oNN = keras.models.load_model(sModelFolderName)\n","    oProcessLog = None\n","    oNN.summary()    \n"],"metadata":{"id":"GyPhQqKB2HXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning Process Overview"],"metadata":{"id":"HdqAw2xpfXz0"}},{"cell_type":"code","source":["if oProcessLog is not None: # [PYTHON] Checks that object reference is not Null\n","    # list all data in history\n","    print(\"Keys of Keras training process log:\", oProcessLog.history.keys())\n","    \n","    sPrefix = \"DA \"\n","            \n","    # summarize history for accuracy\n","    sMetricName = \"root_mean_squared_error\"\n","    plt.plot(oProcessLog.history[sMetricName])\n","    plt.plot(oProcessLog.history[\"val_\" + sMetricName])\n","    plt.title(sPrefix + sMetricName)\n","    plt.ylabel(sMetricName)\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","    \n","    # summarize history for loss\n","    \n","    sCostFunctionNameParts = oCostFunction.name.split(\"_\")                           # [PYTHON]: Splitting string into an array of strings\n","    sCostFunctionNameParts = [x.capitalize() + \" \" for x in sCostFunctionNameParts]  # [PYTHON]: List comprehension example \n","    sCostFunctionName = \" \".join(sCostFunctionNameParts)                             # [PYTHON]: Joining string in a list with the space between them\n","    \n","    \n","    plt.plot(oProcessLog.history['loss'])\n","    plt.plot(oProcessLog.history['val_loss'])\n","    plt.title(sPrefix + sCostFunctionName + \" Error\")\n","    plt.ylabel('Error')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()"],"metadata":{"id":"2vwXe5nBfUtP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference \n","The inference is to feed a set of images and get their reconstructions"],"metadata":{"id":"B2aLiFfZgi7U"}},{"cell_type":"code","source":["# Takes one minibatch out of the dataset. Here the size of the minibatch is the total count of samples\n","for tImages, tTargetImages in oVSData.take(1):\n","    nImages            = tImages.numpy()\n","    nTargetImages      = tTargetImages.numpy()  \n","\n","print(\"VS image features tensor shape:\" , nImages.shape)\n","print(\"VS image targets tensor shape :\" , nTargetImages.shape)\n","\n","nOutputImages = oNN.predict(nImages)"],"metadata":{"id":"dqaqzlbWE4O7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation\n","We can do **qualitative** evaluation to access the quality of our model in contrast to **quantitative** evaluation that uses metrics."],"metadata":{"id":"PZiX2JMoE77-"}},{"cell_type":"code","source":["for nIndex, nOutputImage in enumerate(nOutputImages[0:10,:]):\n","    nOriginalImage = nImages[nIndex]*255.0\n","    nReconstructedImage = nOutputImage*255.0\n","    print(\"-\"*80)\n","    plt.imshow(nOriginalImage[:,:,0].astype(np.uint8), cmap=\"gray\") \n","    plt.title(\"Original image samples #%d\" % (nIndex+1))\n","    plt.show()  \n","    \n","             \n","    plt.imshow(nReconstructedImage[:,:,0].astype(np.uint8), cmap=\"gray\") \n","    plt.title(\"Reconstructed image samples #%d\" % (nIndex+1))\n","    plt.show()    "],"metadata":{"id":"UUPSe4dXgbx7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"9. Deep Convolutional Autoencoder - MNIST.ipynb","provenance":[{"file_id":"1CsDNudi1KDNIXto7hjG_JECo37RbJvHk","timestamp":1611919183124}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}