{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.1 Dataset2D.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOemUDi0cx3MpKdyfiQU3Co"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 3.1 Creating a Random Dataset for Machine Learning \n","This examples illustrates how to create a random dataset with a given number of samples that have a given number of features. The dataset is split into training and validation sets which are visualized.\n"],"metadata":{"id":"aFOTSDqQZj6S"}},{"cell_type":"code","source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/3. Neurons\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/3. Neurons\")\n","print(\"Current dir: \", os.getcwd())"],"metadata":{"id":"MoWCcOx0YOpI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Declare the dataset class\n","#### [Data]\n","* Seeding the random number generators for reproducibility of experiments.\n","* Splitting a dataset.\n","* Normalizing the features.\n","\n","#### [Python]\n","* Import from a package that existing inside the project folder.\n","* Class declaration that implements a random dataset.\n","* Default constructor parameters."],"metadata":{"id":"hqeFBKjxYxp6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3YR8q_tXPTg"},"outputs":[],"source":["import numpy as np                      # use the package (a.k.a. namespace) with the alias \"np\"\n","from sklearn import datasets            # import as single object/subpackage from the package\n","from sklearn.model_selection import train_test_split    # import a standalone procedure function from the pacckage\n","from mllib.utils import RandomSeed                      # custom python package, file inside the package.\n"," \n","\n","# ====================================================================================================\n","class CRandomDataset(object):\n","  # --------------------------------------------------------------------------------------\n","  # Constructor\n","  def __init__(self, p_nSampleCount=200):\n","    # ................................................................\n","    # // Fields \\\\\n","    self.Samples   = None\n","    self.Labels    = None\n","    self.SampleCount = p_nSampleCount\n","\n","    self.TSSamples = None\n","    self.TSLabels  = None\n","    self.TSSampleCount = 0\n","\n","    self.VSSamples = None\n","    self.VSLabels  = None\n","    self.VSSampleCount = 0\n","    # ................................................................\n","\n","    RandomSeed(2022)\n","    self.Samples, self.Labels = datasets.make_classification(\n","        n_features=2,\n","        n_classes=2,\n","        n_samples=self.SampleCount,\n","        n_redundant=0,\n","        n_clusters_per_class=1\n","    )\n","  # --------------------------------------------------------------------------------------\n","  # Method \n","  def DebugPrint(self):\n","    print(\"Shape of sample matrix\", self.Samples.shape)\n","    print('.'*80)\n","\n","    print(\"Datatype of sample matrix before convertion: %s\" % str(self.Samples.dtype))\n","    # Convert the data to 32bit floating point numbers (default for faster computations)\n","    self.Samples = np.asarray(self.Samples, dtype=np.float32)\n","    print(\"Datatype of sample matrix after convertion: %s\" % str(self.Samples.dtype))\n","    print('.'*80)\n","\n","    # Classification into 2 classes == Binary classification\n","    print(\"Class labels\")\n","    print(self.Labels)\n","    print('.'*80)\n","  # --------------------------------------------------------------------------------------\n","  def Split(self):\n","    self.TSSamples, self.VSSamples, self.TSLabels, self.VSLabels = train_test_split(\n","                                                              self.Samples, self.Labels\n","                                                            , test_size=0.10, random_state=2021)\n","        \n","    self.TSSampleCount = self.TSSamples.shape[0]\n","    self.VSSampleCount = self.VSSamples.shape[0]\n","    print(\"%d ssamples in the Training Set\" % self.TSSampleCount)\n","    print(\"%d ssamples in the Validation Set\"%  self.VSSampleCount)\n","    print('.'*80)\n","  # --------------------------------------------------------------------------------------\n","# ====================================================================================================        \n","\n"]},{"cell_type":"markdown","source":["### Use the dataset class from a file\n"],"metadata":{"id":"v5diXcfUbxTy"}},{"cell_type":"code","source":["from Dataset import CRandomDataset"],"metadata":{"id":"0HoBpgYTbYHi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create random dataset \n","It creates the dataset, splits into TS and V, and conditionally normalized the feature values."],"metadata":{"id":"FvqX7J3WbDoK"}},{"cell_type":"code","source":["from sklearn import preprocessing   \n","\n","IS_MINMAX_NORMALIZED = True;\n","\n","oDataset = CRandomDataset(200)\n","oDataset.DebugPrint()\n","\n","# Scale the features to 0 .. 1\n","if IS_MINMAX_NORMALIZED:\n","    print(\"Unscaled sample #1:\", oDataset.Samples[0])\n","    oScaler = preprocessing.MinMaxScaler().fit(oDataset.Samples)\n","    oDataset.Samples = oScaler.transform(oDataset.Samples)\n","    print(\"Minmax normalized sample #1:\", oDataset.Samples[0])\n","\n","oDataset.Split()    "],"metadata":{"id":"FjVk8lDlXgBc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualizing the feature space\n","We can visualize the samples that have only 2 features, because the feature space is 2D.\n","\n","#### [Python]\n","* Using class that encapsulates plots done with the matplotlib library."],"metadata":{"id":"-KzVHRxRZQZC"}},{"cell_type":"code","source":["from mllib.visualization import CPlot    \n","\n","oPlot = CPlot(\"Dataset\", oDataset.Samples, oDataset.Labels)\n","oPlot.Show(IS_MINMAX_NORMALIZED)\n","\n","oPlot = CPlot(\"Training Set\", oDataset.TSSamples, oDataset.TSLabels)\n","oPlot.Show(IS_MINMAX_NORMALIZED)\n","\n","oPlot = CPlot(\"Validation Set\", oDataset.VSSamples, oDataset.VSLabels)\n","oPlot.Show(IS_MINMAX_NORMALIZED)"],"metadata":{"id":"kqDO_ozHZPeP"},"execution_count":null,"outputs":[]}]}