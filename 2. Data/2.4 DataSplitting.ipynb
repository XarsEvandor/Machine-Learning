{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.4 DataSplitting.ipynb","provenance":[{"file_id":"1BwPZQfoQCJoTDkjAb4uAsix6z7s302S0","timestamp":1649238865904}],"collapsed_sections":[],"authorship_tag":"ABX9TyPwCsMihh/AVQ3z45wha+0H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Preparation of Colab runtime environment\n","Mount GDrive, change directory and check contents of folder."],"metadata":{"id":"aFOTSDqQZj6S"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","from google.colab import files\n","\n","drive.mount('/content/gdrive/')\n","print(\"-\"*80)\n","\n","\n","# Change to this source code folder\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/2. Data\")\n","print(\"Current dir: \", os.getcwd())\n","print(\"-\"*40, \"Contents\", \"-\"*40)\n","!ls \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/2. Data\""],"metadata":{"id":"GxIwKbz3ZpdM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Splitting Data\n","* Python: Importing a single method (class) from a package\n","* Python: numpy array shapes\n"],"metadata":{"id":"S3k94_HGdx-y"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","#=================================================================\n","class CDataSet(object):\n","  # --------------------------------------------------------\n","  def __init__(self):\n","    self.IDs = None\n","    self.Targets = None\n","    self.Features = None\n","    self.CategoryIDs = dict()\n","    self.NextID = 0\n","\n","    self.Training = None\n","    self.Validation = None\n","  # ------------------------------------------------------\n","  def LoadFromFile(self, p_sFileName, p_sDelimiter=\";\"):\n","    oDataFrame = pd.read_csv(p_sFileName, delimiter=p_sDelimiter)\n","    oData = oDataFrame.to_numpy();\n","\n","    # Slicing\n","    self.IDs        = oData[:, 0]\n","    self.Targets    = oData[:, 1]\n","    self.Features   = oData[:, 2:]\n","\n","    for nIndex,sTextValue in enumerate(self.Features[:,2]):\n","      if not sTextValue in self.CategoryIDs:\n","        self.CategoryIDs[sTextValue] = self.NextID\n","        self.NextID += 1\n","      nID = self.CategoryIDs[sTextValue]\n","      self.Features[nIndex, 2] = self.NextID\n","    \n","    self.Features = self.Features.astype(np.float32)\n","  # ------------------------------------------------------\n","  def Preprocess(self):\n","    nMinimums = np.min(self.Features, axis=(0))  # Vector of minimum values for each feature\n","    nMaximums = np.max(self.Features, axis=(0))  # vector of maximum values for each feature\n","    print(\"Maximum values of features:\", nMinimums)\n","    print(\"Minimum values of features:\", nMaximums)\n","\n","    for nSampleIndex, nSample in enumerate(self.Features):\n","      nUnscaledFeatureValues = self.Features[nSampleIndex, :]\n","      self.Features[nSampleIndex, :] = (nUnscaledFeatureValues - nMinimums) / (nMaximums - nMinimums)\n","\n","  # ------------------------------------------------------\n","  def Split(self, p_nValidationSamplesPercentage, p_nRandomSeed=2022):\n","    nFeaturesTS, nFeaturesVS, nTargetTS, nTargetVS = train_test_split(self.Features, self.Targets\n","                                                      , test_size=p_nValidationSamplesPercentage\n","                                                      , random_state=p_nRandomSeed)\n","    self.Training  = CDataSet()\n","    self.Training.Features = nFeaturesTS\n","    self.Training.Targets = nTargetTS\n","\n","    self.Validation = CDataSet()\n","    self.Validation.Features = nFeaturesVS\n","    self.Validation.Targets = nTargetVS\n","\n","  # ------------------------------------------------------\n","#=================================================================\n","\n","\n","oDataset = CDataSet()\n","oDataset.LoadFromFile(\"SomeRawData.csv\")\n","oDataset.Preprocess()\n","oDataset.Split(1.0/6.0)\n","\n","\n","print(\"-\"*30, \"Training Set Shapes\", \"-\"*30)\n","print(oDataset.Training.Features.shape)\n","print(oDataset.Training.Targets.shape)\n","\n","print(\"-\"*30, \"Validation Set Shapes\", \"-\"*30)\n","print(oDataset.Validation.Features.shape)\n","print(oDataset.Validation.Targets.shape)\n","\n"],"metadata":{"id":"afFeR4mVdxnz"},"execution_count":null,"outputs":[]}]}