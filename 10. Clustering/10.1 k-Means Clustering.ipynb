{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10.1 k-Means Clustering.ipynb","provenance":[{"file_id":"1CsDNudi1KDNIXto7hjG_JECo37RbJvHk","timestamp":1611919183124}],"collapsed_sections":[],"authorship_tag":"ABX9TyOe+7Ot5vW7UvCi7Jsi353R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KUGvmm_yn1uo"},"source":["# 10.1 Unsupervised Learning with k-Means Clustering\n","\n","This example illustrates clusting on the MNIST and DIGITS image data using the k-Means clustering algorithm. This is done with Unsupervised Learning, without using the label that is provided for each sample. We will use the labels only for visualization."]},{"cell_type":"code","metadata":{"id":"k2taBUomqJHh"},"source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/10. Clustering\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YTqePwJIpLoI"},"source":["# Dataset loading\n","Load either MNIST or DIGITS."]},{"cell_type":"code","metadata":{"id":"JPYGFu4qpK7s"},"source":["from data.digits import CDIGITSDataSet\n","from data.mnist import CMNISTDataSet\n","\n","# _____// Data Hyperparameters \\\\_____\n","IS_MNIST = True\n","SAMPLE_COUNT = 1500  # How many samples to use from the available population in the dataset\n","\n","if IS_MNIST:\n","  oMNIST  = CMNISTDataSet()\n","  sDataName  = \"MNIST\"\n","  nSamples   = oMNIST.TSSamples[:SAMPLE_COUNT,:]\n","  nLabels    = oMNIST.TSLabels[:SAMPLE_COUNT]\n","else:\n","  sDataName = \"DIGITS\"\n","  oDIGITS = CDIGITSDataSet() \n","  nSamples   = oDIGITS.TSSamples[:SAMPLE_COUNT,:]\n","  nLabels    = oDIGITS.TSLabels[:SAMPLE_COUNT]\n","\n","print(\"Loaded %s dataset\" % sDataName)\n","print(\"Training set shape:\", nSamples.shape)\n","print(\"Class count:\", len(np.unique(nLabels)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BNYsR-ronzR"},"source":["# Data Preprocessing.\n","We transform the values of our features with **standardization**, that \"centers\" the mean value for each to 0, lesser values will be negative and greater will be positive. A new value of 1 will mean that its distance from mean is exactly σ the standard deviation."]},{"cell_type":"code","metadata":{"id":"VkTg9laToggH"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","print(\"First sample in dataset, features 40-100, before standardization\")\n","\n","# Standardization\n","nSampleIndex = 0\n","nFromFeature = 140\n","nToFeature = 160\n","\n","oScaler = StandardScaler()\n","nStandardizedSamples = oScaler.fit_transform(nSamples)\n","\n","print(\"Sample#1 original features %d-%d\" % (nFromFeature, nToFeature))\n","print(nSamples[nSampleIndex,nFromFeature:nToFeature])\n","print(\"Mean μ of features %d-%d over %d samples\" % (nFromFeature, nToFeature, SAMPLE_COUNT))\n","print(oScaler.mean_[nFromFeature:nToFeature])\n","print(\"Std σ of features %d-%d over %d samples\" % (nFromFeature, nToFeature, SAMPLE_COUNT))\n","print(oScaler.scale_[nFromFeature:nToFeature])\n","print(\"Sample#1 standardized features %d-%d\" % (nFromFeature, nToFeature))\n","print(nStandardizedSamples[nSampleIndex,nFromFeature:nToFeature])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"imGyA_lKotMp"},"source":["# Dimensionality Reduction.\n","In order to understanding clustering, we would like to visualize the clusters in a 2D space. For this reason we will decrease the initial dimensionality of the image that is 28x28 = 784 to just 2 features, using one of the PCA and t-SNE algorithms."]},{"cell_type":"code","metadata":{"id":"6PQlq3KEoFVB"},"source":["from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","\n","# _____// Dimensionality Reduction Hyperparameters \\\\_____\n","COMPONENTS = 2\n","IS_LINEAR_DIM_REDUCTION = False\n","\n","# ... Dimensionality Reduction Hyperparameters ...\n","PERPLEXITY      = 100.0\n","LEARNING_RATE   = 1000.0\n","EPOCHS          = 1000\n","GRADIENT_CALCULATION_ALGORITHM = \"barnes_hut\" #Fast\n","\n","if IS_LINEAR_DIM_REDUCTION:\n","  sDimReductionMethod = \"PCA\"\n","  nReducedSamples  = PCA(n_components=COMPONENTS).fit_transform(nStandardizedSamples)\n","else:\n","  sDimReductionMethod = \"t-SNE\"\n","  oTSNE = TSNE( n_components=COMPONENTS\n","                ,perplexity=PERPLEXITY, n_iter=EPOCHS\n","                ,method=GRADIENT_CALCULATION_ALGORITHM\n","                ,verbose=2\n","                )\n","  nReducedSamples  = oTSNE.fit_transform(nStandardizedSamples)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualization of Known Classes\n","We visualize the samples as points in the 2D space using a different color for each class."],"metadata":{"id":"Y8BQ61DQ4Ur3"}},{"cell_type":"code","source":["from mllib.visualization import CMultiScatterPlot\n","\n","oPlot = CMultiScatterPlot(\"Visualization of %s image samples after reducing dimensionality with %s\" % (sDataName, sDimReductionMethod))\n","oPlot.AddData(\"\",nReducedSamples , nLabels)\n","oPlot.Show(0, \"Component1\", \"Component2\")"],"metadata":{"id":"94eF0hWr4TyA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1zPkEyO8tpLf"},"source":["# Training\n","Learn a k-Means clustering model.\n","\n"]},{"cell_type":"code","metadata":{"id":"MMF4xokntpaD"},"source":["from sklearn.cluster import KMeans\n","\n","# _____// Clustering Hyperparameters \\\\_____\n","NUM_RUNS_RANDOM_CENTROIDS = 4\n","RANDOM_SEED               = 2021\n","CLUSTER_COUNT_K           = 10\n","\n","nReducedSamples = nReducedSamples.astype(np.float64)\n","oClusteringModel = KMeans(init=\"k-means++\", n_clusters=CLUSTER_COUNT_K, n_init=NUM_RUNS_RANDOM_CENTROIDS, verbose=2)\n","oClusteringModel.fit(nReducedSamples)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KH6fxaEVZ2jp"},"source":["# Visualization of Clusters\n","Visualize the cluster centroids and partitioning of the 2D representation space of an image (after dimensionality reduction) using a Voronoi diagram."]},{"cell_type":"code","metadata":{"id":"EMHql5XMZJl-"},"source":["from mllib.visualization  import CVoronoi2DPlot\n","\n","oVoronoi = CVoronoi2DPlot(\"K-means clustering on %s dataset (%s reduced data)\\n\" \n","                          \"Centroids are marked with white cross\" % (sDataName, sDimReductionMethod)\n","                          ,nReducedSamples, nLabels, p_nGroundTruthClusterCount=10)\n","oVoronoi.ShowForKMeans(oClusteringModel)"],"execution_count":null,"outputs":[]}]}