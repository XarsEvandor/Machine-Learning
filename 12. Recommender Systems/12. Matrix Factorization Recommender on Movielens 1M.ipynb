{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12. Matrix Factorization Recommender on Movielens 1M.ipynb","provenance":[{"file_id":"1CsDNudi1KDNIXto7hjG_JECo37RbJvHk","timestamp":1611919183124}],"collapsed_sections":[],"authorship_tag":"ABX9TyNASP0Z/Dn3u80p1tzCDzUe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KUGvmm_yn1uo"},"source":["# Training the Netflix model on Movielens 1M Datasets\n","We will train this **Matrix Factorization** model that won the Netflix prize in 2009 on the Movielens 1M Dataset. This algorithm approximates **SVD** that can be calculated with linear algebra, using **Gradient Descent** to minimize a reconstruction error.\n"]},{"cell_type":"code","metadata":{"id":"k2taBUomqJHh"},"source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/12. Recommender Systems\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1uCq93lnzWS"},"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","# [PANTELIS] If we want to port an existing model from Tensorflow V1 to the Tensorflow V2 we should use this package and the tfv1 alias for any existing declaration\n","import tensorflow.compat.v1 as tfv1\n","from mllib.utils import RandomSeed\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# __________ | Settings | __________\n","IS_PLOTING_DATA         = True\n","IS_DEBUGABLE            = False\n","IS_RETRAINING           = True\n","RandomSeed(2022)"],"metadata":{"id":"a6q3f1qZ_Oiy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"imGyA_lKotMp"},"source":["# Dataset loading and sample preview"]},{"cell_type":"code","metadata":{"id":"6PQlq3KEoFVB"},"source":["from data.movielens import CMovieLens100K, CMovieLens1M, CMovieLens10M\n","\n","# Loads the dataset and display some validation samples\n","oDataSet = CMovieLens1M()\n","oDataSet.Split(0.8)\n","print(\"Users: %d\" % (oDataSet.UserCount))\n","print(\"Items: %d\" % (oDataSet.ItemCount))\n","print(\"Posible Combinations: %d\" % (oDataSet.UserCount*oDataSet.ItemCount))\n","print(\"Sample Count: %d\" % (oDataSet.SampleCount))\n","\n","\n","if IS_PLOTING_DATA:\n","    print(\"-\"*20, \"Items\", \"-\"*20)\n","    for sKey in list(oDataSet.Items.keys())[0:4]:\n","        print(\"Item ID:%s Name:%s\" % (sKey, oDataSet.Items[sKey]))\n","        \n","    if oDataSet.Users is not None:    \n","        print(\"-\"*20, \"Users\", \"-\"*20)    \n","        for sKey in list(oDataSet.Users.keys())[0:4]:    \n","            print(\"User ID:%s Genre:%s\" % (sKey, oDataSet.Users[sKey]))\n","        \n","    print(\"-\"*20, \"User-Item Samples\", \"-\"*20)\n","    for nIndex, oSample in enumerate(oDataSet.VSSamples[0:4]):\n","        sUserGenre = oDataSet.Users[ oSample[0] ]\n","        sItemName = oDataSet.Items[ oSample[1] ]\n","        nRating = oDataSet.VSLabels[nIndex]\n","        print(\"Sample:%s, Label:%0.1f\" % (oSample, nRating))\n","        print(\"For User-Item combination:[%d (%s), '%s'] the ground truth rating is %.1f\" % (oSample[0], sUserGenre, sItemName, nRating ))\n","        print(\".\"*30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0mxB1GVyMXKc"},"source":["#Training SVD\n","Using a custom implementation in a library Tensorflow Collaborative Filtering (TFCF) that is written in Tensorflow v1. "]},{"cell_type":"code","source":["# __________ | Hyperparameters | __________\n","MODEL_NUMBER = 1\n","CONFIG_BASELINE = {\n","            \"ModelName\": \"SVD_%d\" %  MODEL_NUMBER\n","           ,\"Training.Optimizer\": \"MOMENTUM\"\n","           ,\"Training.MaxEpoch\": 50\n","           ,\"Training.BatchSize\": 4096\n","           ,\"Training.LearningRate\": 1e-4\n","           ,\"Training.Momentum\": 0.5\n","           ,\"Training.RegularizeL2\": True\n","           ,\"Training.WeightDecay\": 3.0\n","          }\n","\n","CONFIG = CONFIG_BASELINE"],"metadata":{"id":"2-asZpeABi3D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference after training\n","Inference in TF v1.0 is done inside the same session"],"metadata":{"id":"ifb5VNqcBqFx"}},{"cell_type":"code","metadata":{"id":"EMHql5XMZJl-"},"source":["from tfcf.metrics import mae\n","from tfcf.metrics import rmse\n","from tfcf.config import Config\n","from tfcf.models.svd import SVD\n","from tfcf.models.svdpp import SVDPP\n","\n","# Creates a Tensorflow v1 session. This is done behind the scenes with Keras in version above 2.0\n","with tfv1.Session() as oSession:\n","    if IS_DEBUGABLE:\n","        tf.compat.v1.enable_eager_execution()\n","        \n","    oModel = SVD(oSession, p_oConfig=CONFIG, p_oDataSet=oDataSet)\n","    sModelFolder = os.path.join(\"MLModel\", CONFIG[\"ModelName\"])\n","\n","    if not os.path.exists(sModelFolder) or IS_RETRAINING:\n","      nMeanRating = np.mean(oDataSet.TSLabels)\n","        \n","      oModel.train(oDataSet.TSSamples, oDataSet.TSLabels,\n","                   validation_data=(oDataSet.VSSamples, oDataSet.VSLabels),\n","                   epochs=CONFIG[\"Training.MaxEpoch\"], batch_size=CONFIG[\"Training.BatchSize\"], p_nMeanRating=nMeanRating)\n","      \n","      # Saves a tensorflow graph to a folder\n","      if not os.path.exists(sModelFolder):\n","        os.makedirs(sModelFolder)\n","      oModel.SaveModel(sModelFolder)\n","    else:\n","      # Loads a tensorflow graph from a folder\n","      oModel.LoadModel(sModelFolder)\n","\n","\n","    print(\"-\"*30, \"Predicting recommended items\", \"-\"*30)\n","    y_true = oDataSet.VSLabels\n","    y_pred = oModel.predict(oDataSet.VSSamples)      "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cNHTYEeLZsLt"},"source":["# Inference\n","The samples are combinations of (UserID, ItemID) and the output is a floating point value for the predicted rating from 0 to 5.\n"]},{"cell_type":"code","metadata":{"id":"-fm00oFFZpNr"},"source":["print(\"First four samples:\")\n","for nIndex, oSample in enumerate(oDataSet.VSSamples[0:4]):\n","    print(\"Combination User-Item:%s  Ground Truth Rating:%d    Predicted Rating:%d\" % (oSample, y_true[nIndex], y_pred[nIndex]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation\n","Assembling the user-item matrix from ratings that correspond to pairs"],"metadata":{"id":"27G9_NZMCRMm"}},{"cell_type":"code","source":["# Creating the user-item ratings matrix. We need the maximum ID because there might be missing IDs in the series \n","oTruePerUserRankedRatings       = np.zeros( (oDataSet.MaxUserID, oDataSet.MaxItemID) , np.float32)\n","oPredictedPerUserRankedRatings  = np.zeros( (oDataSet.MaxUserID, oDataSet.MaxItemID) , np.float32)\n","for nIndex, oSample in enumerate(oDataSet.VSSamples):\n","    nUserID = int(oSample[0])\n","    nItemID = int(oSample[1])\n","    nRating = oDataSet.VSLabels[nIndex]\n","    nPredictedRating = y_pred[nIndex]\n","    oTruePerUserRankedRatings[nUserID, nItemID] = nRating\n","    oPredictedPerUserRankedRatings[nUserID, nItemID] = nPredictedRating"],"metadata":{"id":"v84M20VdCVZz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Root Mean Squared Error"],"metadata":{"id":"1M-YvBTEDtQy"}},{"cell_type":"code","source":["print(\"-\"*30, \"Evaluating model %s\" % CONFIG[\"ModelName\"], \"-\"*30)\n","print('rmse: {}, mae: {}'.format(rmse(y_true, y_pred), mae(y_true, y_pred)))\n"],"metadata":{"id":"M0jlgxT5Do-w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mean Reciprocal Rank\n","We can choose the count of recommended items to perform an evaluation of a ranked set of predictions. We can restrict the evaluation to users with few rating or users with many ratings."],"metadata":{"id":"le8SGEugDwJM"}},{"cell_type":"code","source":["# For each user row in the array gets the sorted by rating in descending order indices, that correspond to ItemIDs.\n","RECOMMENDED_ITEMS = 25\n","FILTER_BY_CASUAL_VIEWER = True\n","FILTER_BY_MOVIE_CRITICS = False\n","nCasualViewerLimit  = 20\n","nMovieCriticsLimit  = 100\n","\n","if FILTER_BY_CASUAL_VIEWER:\n","    print(\"--- For users that have rated a few movies (casual viewers) ---\")\n","elif FILTER_BY_MOVIE_CRITICS:\n","    print(\"--- For users that have rated a lot of movies movies (movie critics) ---\")\n","        "],"metadata":{"id":"g6auHxEzCcI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bPrinted = False\n","nSumReciprocalRank = 0.0\n","nCountUsers = 0\n","nFoundUsers = 0\n","for nIndex, oTrueUserRatings in enumerate(oTruePerUserRankedRatings):\n","    oPredictedUserRatings = oPredictedPerUserRankedRatings[nIndex,:]\n","    \n","    nCountOfRatings = np.count_nonzero(oTrueUserRatings) \n","    bInclude = (nCountOfRatings > 0)\n","    if bInclude:\n","        if FILTER_BY_CASUAL_VIEWER:\n","            bInclude = nCountOfRatings <= nCasualViewerLimit\n","        elif FILTER_BY_MOVIE_CRITICS:\n","            bInclude = nCountOfRatings >= nMovieCriticsLimit \n","    \n","    if bInclude: \n","        oTrueTopItemsForUser = np.argsort(-oTrueUserRatings)[:RECOMMENDED_ITEMS]\n","        oTrueTopRatings      = oTrueUserRatings[oTrueTopItemsForUser]\n","        #print(oTrueTopItemsForUser)\n","        #print(oTrueTopRatings)\n","\n","        oPredictedTopItemsForUser  = np.argsort(-oPredictedUserRatings)[:RECOMMENDED_ITEMS] \n","        oPredictedTopRatings = oPredictedUserRatings[oPredictedTopItemsForUser]\n","        #print(oPredictedTopItemsForUser)\n","        #print(oPredictedTopRatings)\n","        \n","        nFound = np.where(oTrueTopItemsForUser == oPredictedTopItemsForUser[0])\n","        nFound = nFound[0]\n","        nReciprocalRank = 0.0\n","        if nFound:\n","            if len(nFound) > 0:\n","                nFoundUsers += 1\n","                nRank = float(nFound[0])+1.0\n","                nReciprocalRank = 1.0 / nRank\n","                \n","            if not bPrinted:\n","                bPrinted = True\n","                print(\". \"*20)\n","                print(\"Ground truth items and ratings for user %d\" % (nIndex+1))\n","                print(oTrueTopItemsForUser)\n","                print(oTrueTopRatings)\n","                print(\". \"*20)\n","                print(\"Predicted items and ratings for user %d\" % (nIndex+1))\n","                print(oPredictedTopItemsForUser)\n","                print(oPredictedTopRatings)\n","                print(\". \"*20)\n","                print(\"Position in ground truth of top recommendation (Rank):%.0f\" % nRank)\n","                print(\". \"*20)\n","            \n","        nSumReciprocalRank += nReciprocalRank\n","        nCountUsers += 1"],"metadata":{"id":"Bj_yDDQODyR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nMeanReciprocalRank = nSumReciprocalRank/ nCountUsers\n","print(\"Mean Reciprocal Rank for %d user recommendations is %.6f\" % (nCountUsers, nMeanReciprocalRank ))\n","print(\"this means that the model presents the correct prediction at average rank %.0f\" % (1.0 / nMeanReciprocalRank))     \n","print(\"The model recommended an item that exists in the top %d/%d items for %d users\" % (RECOMMENDED_ITEMS, oDataSet.ItemCount, nFoundUsers ))\n"],"metadata":{"id":"rYFUEj6uD2Qq"},"execution_count":null,"outputs":[]}]}