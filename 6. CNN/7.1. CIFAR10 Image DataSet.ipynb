{"cells":[{"cell_type":"markdown","metadata":{"id":"hNsGWfAPSkxl"},"source":["# 7.1 CIFAR10 Image Dataset\n","The following code will download the CIFAR10 32x32 color image dataset, and assemble a cache of samples, stored in pickle files. This cache will be ready to use by the training process of a Convolutional Neural Network (CNN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"suS5EAt4BQmT"},"outputs":[],"source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/6. CNN\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())"]},{"cell_type":"markdown","metadata":{"id":"8l9GJdujfoIR"},"source":["## Dataset class\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liqbtWhuhmU7"},"outputs":[],"source":["# ......................................................................................\n","# MIT License\n","\n","# Copyright (c) 2021 Pantelis I. Kaplanoglou\n","\n","# Permission is hereby granted, free of charge, to any person obtaining a copy\n","# of this software and associated documentation files (the \"Software\"), to deal\n","# in the Software without restriction, including without limitation the rights\n","# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","# copies of the Software, and to permit persons to whom the Software is\n","# furnished to do so, subject to the following conditions:\n","\n","# The above copyright notice and this permission notice shall be included in all\n","# copies or substantial portions of the Software.\n","\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","# SOFTWARE.\n","\n","# ......................................................................................\n","\n","import pickle\n","import numpy as np\n","import sys\n","import os\n","import scipy.stats as stats\n","from mllib.filestore import CFileStore\n","from mllib.data import CCustomDataSet\n","from datasets.cifar10.downloader import CDataSetDownloaderCIFAR10\n","\n","\n","# =========================================================================================================================\n","class CCIFAR10DataSet(CCustomDataSet):\n","  # --------------------------------------------------------------------------------------\n","  def __init__(self, p_bIsVerbose=False):\n","    super(CCIFAR10DataSet, self).__init__()\n","    # ................................................................\n","    # // Fields \\\\\n","    self.IsVerbose = p_bIsVerbose\n","\n","    self.DataSetFolder = os.path.join(\"MLData\", \"cifar10\")\n","\n","    self.ClassCount         = 10\n","    self.ClassNames         = [  \"airplane\", \"automobile\", \"bird\", \"cat\",\"deer\"\n","                               , \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n","                               ]\n","    self.FeatureCount       = 32*32*3\n","    self.ImageShape         = [32, 32, 3]\n","\n","\n","    self.BatchesFile                = os.path.join(self.DataSetFolder, 'batches.meta')\n","    self.TrainingShardFileTemplate  = os.path.join(self.DataSetFolder, 'data_batch_%d')\n","    self.TestFileName               = os.path.join(self.DataSetFolder, 'test_batch')\n","\n","    \n","    self.FileStore = CFileStore(self.DataSetFolder)\n","    # ................................................................\n","\n","    # Lazy dataset initialization. Try to load the data and if not already cached to local filestore, generate the samples now and cache them.\n","    self.TSSamples = self.FileStore.Deserialize(\"CIFAR10-TSSamples.pkl\")\n","    self.TSLabels  = self.FileStore.Deserialize(\"CIFAR10-TSLabels.pkl\")\n","\n","    self.VSSamples = self.FileStore.Deserialize(\"CIFAR10-VSSamples.pkl\")\n","    self.VSLabels  = self.FileStore.Deserialize(\"CIFAR10-VSLabels.pkl\")\n","\n","    if self.TSSamples is None:\n","      self.CreateDatasetCache()\n","\n","      self.FileStore.Serialize(\"CIFAR10-TSSamples.pkl\", self.TSSamples)\n","      self.FileStore.Serialize(\"CIFAR10-TSLabels.pkl\", self.TSLabels)\n","      \n","      self.FileStore.Serialize(\"CIFAR10-VSSamples.pkl\", self.VSSamples)\n","      self.FileStore.Serialize(\"CIFAR10-VSLabels.pkl\", self.VSLabels)\n","\n","\n","\n","  # --------------------------------------------------------------------------------------\n","  def CreateDatasetCache(self):\n","    oDownloader = CDataSetDownloaderCIFAR10()\n","    oDownloader.Download()\n","\n","    self.LoadSubset(True)\n","    self.LoadSubset(False)\n","    \n","    self.SampleCount      = self.TSSampleCount + self.VSSampleCount\n","    self.FeatureCount     = np.prod(self.TSSamples.shape[1:])\n","    self.ClassCount       = len(np.unique(self.TSLabels))\n","\n","    print(\"Classes:\", self.ClassCount)\n","  # --------------------------------------------------------------------------------------------------------\n","  def AppendTrainingShard(self, p_nSamples, p_nLabels):\n","    # First shard initializes training set, next shards are appended\n","    if self.TSSamples is None:\n","      self.TSSamples = p_nSamples\n","      self.TSSampleCount = 0\n","    else:\n","      self.TSSamples = np.concatenate((self.TSSamples, p_nSamples), axis=0)\n","\n","    if self.TSLabels is None:\n","      self.TSLabels = p_nLabels\n","    else:\n","      self.TSLabels = np.concatenate((self.TSLabels, p_nLabels), axis=0)\n","      \n","    self.TSSampleCount += p_nSamples.shape[0]\n","  # --------------------------------------------------------------------------------------------------------\n","  def AppendValidationShard(self, p_nSamples, p_nLabels):\n","    # First shard initializes test (validation) set, next shards are appended\n","    if self.VSSamples is None:\n","      self.VSSamples = p_nSamples\n","      self.VSSampleCount = 0\n","    else:\n","      self.VSSamples = np.concatenate((self.VSSamples, p_nSamples), axis=0)\n","\n","    if self.VSLabels is None:\n","      self.VSLabels = p_nLabels\n","    else:\n","      self.VSLabels = np.concatenate((self.VSLabels, p_nLabels), axis=0)        \n","\n","    self.VSSampleCount += p_nSamples.shape[0]\n","  # --------------------------------------------------------------------------------------------------------\n","  def _transposeImageChannels(self, p_nX, p_nShape=(32, 32, 3), p_bIsFlattening=False):\n","    \"\"\"\n","    This method create image tensors (Spatial_dim, Spatial_dim, Channels) from image vectors of 32x32x3 features\n","    \"\"\"\n","    nResult = np.asarray(p_nX, dtype=np.float32)\n","    nResult = nResult.reshape([-1, p_nShape[2], p_nShape[0], p_nShape[1]])\n","    nResult = nResult.transpose([0, 2, 3, 1])\n","        \n","    if p_bIsFlattening:\n","      nResult = nResult.reshape(-1, np.prod(np.asarray(p_nShape)))\n","        \n","    return nResult \n","  # --------------------------------------------------------------------------------------------------------\n","  def LoadSubset(self, p_bIsTrainingSet=True):\n","    if p_bIsTrainingSet:\n","      for i in range(5):\n","        with open(self.TrainingShardFileTemplate % (i+1), 'rb') as oFile:\n","          oDict = pickle.load(oFile, encoding='latin1')\n","          oFile.close()\n","        self.AppendTrainingShard(self._transposeImageChannels(oDict[\"data\"], (32,32,3)), np.array(oDict['labels'], np.uint8))\n","    else:\n","      with open(self.TestFileName, 'rb') as oFile:\n","        oDict = pickle.load(oFile, encoding='latin1')\n","        oFile.close()\n","      self.AppendValidationShard(self._transposeImageChannels(oDict[\"data\"], (32,32,3)), np.array(oDict['labels'], np.uint8))\n","  # --------------------------------------------------------------------------------------\n","# =========================================================================================================================\n","\n","\n","if __name__ == \"__main__\":\n","  oDataSet = CCIFAR10DataSet()\n","  print(\"Test set shape:\", oDataSet.TSSamples.shape)\n","  print(\"Validation set shape:\", oDataSet.VSSamples.shape)"]},{"cell_type":"markdown","metadata":{"id":"XbXPSrV2NutA"},"source":["Browse some tiny images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AW9nsdD0NvZk"},"outputs":[],"source":["import sys\n","import matplotlib.pyplot as plt\n","\n","for nIndex, nSample in enumerate(oDataSet.TSSamples):\n","  nLabel = oDataSet.TSLabels[nIndex]\n","  if nIndex == 9: \n","    nImage =  nSample.astype(np.uint8) # Show the kitty\n","    print(nImage.shape)\n","    print(oDataSet.ClassNames[nLabel])\n","    plt.imshow(nImage[4:22, 0:15, :])\n","    plt.show()    \n","\n","  elif nIndex == 30: # Show the toy airplane\n","    nImage =  nSample.astype(np.uint8)\n","    print(nImage.shape)\n","    print(oDataSet.ClassNames[nLabel])\n","    plt.imshow(nImage)\n","    plt.show()      \n","\n","\n","    plt.title(\"Blue\")\n","    plt.imshow(nImage[:,:,0], cmap=\"Blues\")\n","    plt.show()    \n","    \n","    plt.title(\"Green\")\n","    plt.imshow(nImage[:,:,1], cmap=\"Greens\")\n","    plt.show()    \n","\n","    plt.title(\"Red\")\n","    plt.imshow(nImage[:,:,2], cmap=\"Reds\")\n","    plt.show()                \n"]}],"metadata":{"colab":{"name":"7.1. CIFAR10 Image DataSet.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}