{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6.2 CNN for Grayscale Image Classification with Keras.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM0DV0l1775ImgD9Mj529gf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 6.2 Training a basic Convolutional Neural Network for classification of grayscale images of handwritten digits\n","This examples illustrates a basic CNN in Tensorflow/Keras, trained to classify handwritten digits from their grayscale images. It uses the well-known MNIST dataset. Except the convolutional layers it supports **Max Pooling** layers and **Normalization Layers** that are helpful for the stability of the learning process. "],"metadata":{"id":"DojV2IqZcaom"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0m8s-KccaJp"},"outputs":[],"source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/6. CNN\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())"]},{"cell_type":"markdown","source":["# Settings and Basic Package Imports"],"metadata":{"id":"y0TJgTCXbfrZ"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from mllib.utils import RandomSeed\n","\n","# __________ | Settings | __________\n","IS_PLOTING_DATA         = True\n","IS_DEBUGABLE            = False\n","IS_RETRAINING           = True\n","RandomSeed(2022)"],"metadata":{"id":"kIrldDF0bgGt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameters\n","For each training experiment, we define all the model/training hyperparameters inside a Python dictionary."],"metadata":{"id":"5z0Jm3SFxJWv"}},{"cell_type":"code","source":["CONFIG_BASELINE = {\n","                      \"ModelName\": \"MNIST1\"  \n","                    ,\"DNN.InputFeatures\": 28*28\n","                    ,\"DNN.LayerNeurons\": [512,10]\n","                    ,\"DNN.Classes\": 10\n","                    ,\"Training.MaxEpoch\": 20\n","                    ,\"Training.BatchSize\": 500\n","                    ,\"Training.LearningRate\": 0.3\n","                  }\n","CONFIG_CNN = {\n","                 \"ModelName\": \"MNIST_CNN1\"\n","                ,\"CNN.InputShape\": [28,28,1]\n","                ,\"CNN.Classes\": 10\n","                ,\"CNN.ModuleCount\": 6\n","                ,\"CNN.ConvOutputFeatures\": [9,16,24,32,48,48]\n","                ,\"CNN.ConvWindows\": [ [3,2,True], [3,1,True] ,  [3,1,True], [3,2,True], [3,1,True], [3,1,True] ]\n","                ,\"CNN.PoolWindows\": [  None      , None       ,  None      , None      , [3,2]     , None      ]\n","                ,\"CNN.HasBatchNormalization\": True\n","                ,\"Training.MaxEpoch\": 12\n","                ,\"Training.BatchSize\": 500\n","                ,\"Training.LearningRate\": 0.001               \n","            }\n","                     "],"metadata":{"id":"-fGhVtyRneUP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We choose the hyperparameter set for the current model training experiment"],"metadata":{"id":"5QwJ_PBpbwOP"}},{"cell_type":"code","source":["CONFIG = CONFIG_CNN\n","IS_CNN = CONFIG == CONFIG_CNN"],"metadata":{"id":"YnqkfSVqbuPa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MNIST\n","This [MNIST dataset](http://yann.lecun.com/exdb/mnist/) dataset, that dates back to 1998, has become a standard toy dataset to understand the image classification task. It contains 70000 grayscale images of 28x28 dimensions for the handwritten digits 0,1,..9. \n","It is already splitted into a training set of 60000 images, while the rest 10000 are used to validate the model\n","\n","# Dataset loading and previewing\n","We are reusing an existing dataset in Tensorflow format. We load the data and extract them as numpy arrays to view some images, and later use the target class labels for evaluation."],"metadata":{"id":"Cc5voM78xgaC"}},{"cell_type":"code","source":["import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","\n","(oTSData, oVSData), oDataSetInfo = tfds.load(\n","    'mnist',\n","    split=['train', 'test'],\n","    shuffle_files=True,\n","    as_supervised=True,\n","    with_info=True,\n",")\n","  \n","# Takes one minibatch out of the dataset. Here the size of the minibatch is the total count of samples\n","for tImages, tLabels in oVSData.batch(oDataSetInfo.splits['test'].num_examples).take(1):\n","    nImages            = tImages.numpy()\n","    nTargetClassLabels = tLabels.numpy()  \n","\n","print(\"VS image features tensor shape:\" , nImages.shape)\n","print(\"VS image targets vector shape :\", nTargetClassLabels.shape)\n","\n","if IS_PLOTING_DATA:\n","    for nIndex, nSample in enumerate(nImages):\n","      nLabel = nTargetClassLabels[nIndex]\n","      if (nIndex >= 0 and nIndex <= 20):\n","           \n","        if nIndex == 0:\n","            print(\"Image sample shape            :\", nSample.shape)\n","        nImage =  nSample.astype(np.uint8) \n","        plt.imshow(nImage[:,:,0], cmap=\"gray\") #https://matplotlib.org/stable/tutorials/colors/colormaps.html\n","        #plt.imshow(nImage[4:22, 0:15, :], cmap=\"gray\") #https://matplotlib.org/stable/tutorials/colors/colormaps.html\n","        plt.title(\"Digit %d\" % nLabel)\n","        plt.show()    "],"metadata":{"id":"GxOxQ9AkxYvu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tensorflow/Keras data feeding pipelines\n","We are going to create a pipeline that will feed our training process with data. There is a method used with `map()` that is called for each sample to normalize the value, reshape its features shape and create one-hot encodings for its label. The pipeline uses\n","* `cache`: To cache the data in memory\n","* `shuffle`: To shuffly the samples at each step\n","* `batch`: To create mini-batches of samples\n","* `prefetch`: To use multi-threading for loading the samples into the learning process."],"metadata":{"id":"F3SX-nT0cKTo"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------------\n","def NormalizeAndReshapeImage(p_tImage, p_tLabel):\n","    # Normalizes color component values from `uint8` to `float32`.\n","    tNormalizedImage = tf.cast(p_tImage, tf.float32) / 255.\n","    # Reshapes the 3D tensor of the image (28x28x1) into a 782-dimensional vector\n","    tNormalizedImage = tf.reshape(tNormalizedImage, [CONFIG[\"DNN.InputFeatures\"]])\n","    # Target class labels into one-hot encoding\n","    tTargetOneHot = tf.one_hot(p_tLabel, CONFIG[\"DNN.Classes\"])\n","    \n","    return tNormalizedImage, tTargetOneHot\n","# -----------------------------------------------------------------------------------\n","def NormalizeImage(p_tImage, p_tLabel):\n","    # Normalizes color component values from `uint8` to `float32`.\n","    tNormalizedImage = tf.cast(p_tImage, tf.float32) / 255.\n","    # Target class labels into one-hot encoding\n","    tTargetOneHot = tf.one_hot(p_tLabel, CONFIG[\"CNN.Classes\"])\n","    \n","    return tNormalizedImage, tTargetOneHot\n","# -----------------------------------------------------------------------------------\n","\n","\n","nBatchSize = CONFIG[\"Training.BatchSize\"]\n","\n","# ...... Training data feed pipeline ......\n","if IS_CNN:\n","  # For a Convolutional Neural Network we use a 3D tensor as input\n","  oTSData = oTSData.map(NormalizeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","else:\n","  # For an MLP Neural Network we use the reshaped image vector a input\n","  oTSData = oTSData.map(NormalizeAndReshapeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","    \n","oTSData = oTSData.cache()\n","oTSData = oTSData.shuffle(oDataSetInfo.splits['train'].num_examples)\n","oTSData = oTSData.batch(nBatchSize)\n","oTSData = oTSData.prefetch(tf.data.AUTOTUNE)\n","print(\"Training data feed object:\", oTSData)\n","\n","# ...... Validation data feed pipeline ......\n","if IS_CNN:\n","  oVSData = oVSData.map(NormalizeImage, num_parallel_calls=tf.data.AUTOTUNE)    \n","else:\n","  oVSData = oVSData.map(NormalizeAndReshapeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","    \n","oVSData = oVSData.batch(oDataSetInfo.splits['test'].num_examples)\n","print(\"Validation data feed object:\", oVSData)"],"metadata":{"id":"0NK7VS2ocKm4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convolutional Neural Network Class\n","We declare the class for a **Convolutional Deep Neural Network (CNN)** that has a variable depth of convolutional layers and support for max pooling layers after each convolutional layer."],"metadata":{"id":"rBjC2F3Blqs4"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras.layers import InputLayer, Flatten, Dense, BatchNormalization, Activation, Softmax\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D  \n","from tensorflow.keras.regularizers import L2\n","# =========================================================================================================================\n","class CCNNCustom(keras.Model):\n","  # --------------------------------------------------------------------------------------\n","  # Constructor\n","  def __init__(self, p_oConfig):\n","    super(CCNNCustom, self).__init__()\n","    \n","    # ..................... Object Attributes ...........................\n","    self.Config = p_oConfig\n","    \n","    self.InputShape         = self.Config[\"CNN.InputShape\"]\n","    self.ClassCount         = self.Config[\"CNN.Classes\"]\n","    self.ModuleCount        = self.Config[\"CNN.ModuleCount\"]\n","    \n","    self.ConvLayerFeatures  = self.Config[\"CNN.ConvOutputFeatures\"]\n","    self.ConvWindows        = self.Config[\"CNN.ConvWindows\"]\n","    self.PoolWindows        = self.Config[\"CNN.PoolWindows\"]\n","    \n","    if \"CNN.HasBatchNormalization\" not in self.Config:\n","        self.Config[\"CNN.HasBatchNormalization\"] = False\n","    \n","    self.KerasLayers        = []\n","\n","    self.OutputLayer        = None\n","    self.SoftmaxActivation  = None\n","    self.Input              = None\n","    self.Structure          = None\n","    # ...................................................................\n","    \n","    # Default values for extra customization\n","    \n","    if \"CNN.ActivationFunction\" not in self.Config:\n","        self.Config[\"CNN.ActivationFunction\"] = \"relu\"\n","                \n","    if \"CNN.ConvHasBias\" not in self.Config:\n","        self.Config[\"CNN.ConvHasBias\"] = False\n","\n","    if \"CNN.KernelInitializer\" not in self.Config:\n","        self.Config[\"CNN.KernelInitializer\"] = \"glorot_uniform\"\n","\n","    if \"CNN.BiasInitializer\" not in self.Config:\n","        self.Config[\"CNN.BiasInitializer\"] = \"zeros\"\n","\n","    if \"Training.RegularizeL2\" not in self.Config:\n","        self.Config[\"Training.RegularizeL2\"] = False\n","                 \n","    if \"Training.WeightDecay\" not in self.Config:\n","        self.Config[\"Training.WeightDecay\"] =  1e-5\n","        \n","    if self.Config[\"Training.RegularizeL2\"]:\n","        print(\"Using L2 regularization of weights with weight decay %.6f\" % self.Config[\"Training.WeightDecay\"])\n","\n","                                    \n","    self.Create()\n","  # --------------------------------------------------------------------------------------\n","  def Create(self):                # override a virtual in our base class\n","    # This loop creates stacked convolutional modules of the form   CONVOLUTION - ACTIVATION - NORMALIZATION - MAX POOLING\n","    for nModuleIndex in range(0, self.ModuleCount):\n","      nFeatures     = self.ConvLayerFeatures[nModuleIndex]\n","      oConvWindowSetup = self.ConvWindows[nModuleIndex]\n","      nWindowSize   = oConvWindowSetup[0]\n","      nStride       = oConvWindowSetup[1]\n","      \n","      sPaddingType      = \"valid\"\n","      if len(oConvWindowSetup) == 3:\n","          bIsPadding    = oConvWindowSetup[2]\n","          if bIsPadding:\n","              sPaddingType = \"same\"\n","      \n","      if self.Config[\"Training.RegularizeL2\"]:\n","          oWeightRegularizer = L2(self.Config[\"Training.WeightDecay\"])\n","      else:\n","          oWeightRegularizer = None\n","                        \n","      oConvolution = Conv2D(nFeatures, kernel_size=nWindowSize, strides=nStride, padding=sPaddingType\n","                            , use_bias=self.Config[\"CNN.ConvHasBias\"]\n","                            , kernel_regularizer=oWeightRegularizer\n","                            , kernel_initializer=self.Config[\"CNN.KernelInitializer\"]\n","                            , bias_initializer=self.Config[\"CNN.BiasInitializer\"])\n","      self.KerasLayers.append(oConvolution)\n","      \n","      oActivation  = Activation(self.Config[\"CNN.ActivationFunction\"])\n","      self.KerasLayers.append(oActivation)\n","      \n","      if self.Config[\"CNN.HasBatchNormalization\"]:\n","          oNormalization = BatchNormalization()\n","          self.KerasLayers.append(oNormalization)\n","      \n","      oPoolWindow   = self.PoolWindows[nModuleIndex]\n","      # Set the pool size to None for a module that does not do Max Pooling.\n","      if oPoolWindow is not None:\n","          nPoolSize   = oPoolWindow[0]\n","          nPoolStride = oPoolWindow[1]\n","          oMaxPooling = MaxPooling2D(pool_size=[nPoolSize, nPoolSize], strides=[nPoolStride, nPoolStride])\n","          self.KerasLayers.append(oMaxPooling)\n","          \n","    \n","    # After the stack of convolutional modules, the activation cube will be flattened to a vector using a Flatten keras layer\n","    self.FlatteningLayer = Flatten()\n","    \n","    \n","    # The output layer for the classifier is a fully connected (dense) that has one neuron for each class.\n","    # You might consider the stack of convolutional modules functioning as the \"hidden\" layer in the 2-layer NN architecture.\n","    if self.Config[\"Training.RegularizeL2\"]:\n","        oWeightRegularizer = L2(self.Config[\"Training.WeightDecay\"])\n","    else:\n","        oWeightRegularizer = None          \n","    self.OutputLayer = Dense(self.ClassCount, use_bias=True\n","                             ,kernel_regularizer=oWeightRegularizer )\n","    \n","    # Instead of using sigmoid for each neuron, we use the softmax activation function so that neuron \"fire\" together. \n","    self.SoftmaxActivation = Softmax()           \n","  # --------------------------------------------------------------------------------------------------------\n","  def call(self, p_tInput):        # overrides a virtual in keras.Model class\n","    bPrint = self.Structure is None\n","    if bPrint:\n","        self.Structure = []\n","      \n","    self.Input = p_tInput\n","    \n","    # ....... Convolutional Feature Extraction  .......\n","    # Feed forward to the next layer\n","    tA = p_tInput\n","    for nIndex,oKerasLayer in enumerate(self.KerasLayers):\n","        if bPrint:\n","            self.Structure.append([nIndex + 1, str(tA.name), str(tA.shape)])         \n","        tA = oKerasLayer(tA)\n","\n","    # Flattens the activation cube to a vector\n","    tA = self.FlatteningLayer(tA)\n","    if bPrint:\n","        nIndex += 1\n","        self.Structure.append([nIndex + 1, str(tA.name), str(tA.shape)])        \n","    \n","    # ....... Classifier  .......\n","    # Fully connected (dense) layer that has a count of neurons equal to the classes, with softmax activation function\n","    tA = self.OutputLayer(tA)\n","    if bPrint:\n","        nIndex += 1\n","        self.Structure.append([nIndex + 1, str(tA.name), str(tA.shape)])        \n","    \n","    tA = self.SoftmaxActivation(tA)\n","    if bPrint:\n","        nIndex += 1\n","        self.Structure.append([nIndex + 1, str(tA.name), str(tA.shape)])        \n","        \n","    \n","    return tA\n","  # --------------------------------------------------------------------------------------\n","# ========================================================================================================================="],"metadata":{"id":"v73nWhSOdLt3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create the Neural Network model and training algorithm objects\n"],"metadata":{"id":"DhT1bvZudWDr"}},{"cell_type":"code","source":["from models.CNN import CCNNBasic\n","\n","oNN = CCNNBasic(CONFIG)\n","\n","# -----------------------------------------------------------------------------------\n","def LRSchedule(epoch, lr):\n","    if epoch == 10:\n","        nNewLR = lr * 0.5\n","        print(\"Setting LR to %.5f\" % nNewLR)\n","        return nNewLR\n","    else:\n","        return lr\n","# -----------------------------------------------------------------------------------    \n","\n","nInitialLearningRate    = CONFIG[\"Training.LearningRate\"]    \n","\n","oCostFunction   = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","oOptimizer = tf.keras.optimizers.Adam(learning_rate=nInitialLearningRate)\n","oCallbacks = None   "],"metadata":{"id":"Lw53Davlln-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Process"],"metadata":{"id":"kzI7KKYznfBi"}},{"cell_type":"code","source":["sModelFolderName = CONFIG[\"ModelName\"]\n","        \n","if (not os.path.isdir(sModelFolderName)) or IS_RETRAINING:\n","    oNN.compile(loss=oCostFunction, optimizer=oOptimizer, metrics=[\"accuracy\"])\n","\n","    if IS_DEBUGABLE:\n","        oNN.run_eagerly = True\n","        \n","    oProcessLog = oNN.fit(  oTSData, batch_size=nBatchSize\n","                            ,epochs=CONFIG[\"Training.MaxEpoch\"]\n","                            ,validation_data=oVSData\n","                            ,callbacks=oCallbacks\n","                          )\n","    oNN.summary()          \n","    oNN.save(sModelFolderName)      \n","else:\n","    # The model is trained and its state is saved (all the trainable parameters are saved). We load the model to recall the samples \n","    oNN = keras.models.load_model(sModelFolderName)\n","    oProcessLog = None\n","    oNN.summary()    "],"metadata":{"id":"3Pqd9bgmcdMx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Architecture Overview"],"metadata":{"id":"-sq6PkuMHRyM"}},{"cell_type":"code","source":["import csv\n","\n","with open(\"Model-Structure-%s.csv\" % CONFIG[\"ModelName\"], 'w') as f: \n","    write = csv.writer(f)\n","    for oItem in oNN.Structure:\n","        print(oItem) \n","        write.writerow(oItem) "],"metadata":{"id":"qCFnBfarHSZQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning Process Overview"],"metadata":{"id":"HdqAw2xpfXz0"}},{"cell_type":"code","source":["if oProcessLog is not None: # [PYTHON] Checks that object reference is not Null\n","    # list all data in history\n","    print(\"Keys of Keras training process log:\", oProcessLog.history.keys())\n","    \n","    # Plot the accuracy during the training epochs\n","    plt.plot(oProcessLog.history['accuracy'])\n","    plt.plot(oProcessLog.history['val_accuracy'])\n","    plt.title('CNN Accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","    \n","    # Plot the error during the training epochs\n","    sCostFunctionNameParts = oCostFunction.name.split(\"_\")                           # [PYTHON]: Splitting string into an array of strings\n","    sCostFunctionNameParts = [x.capitalize() + \" \" for x in sCostFunctionNameParts]  # [PYTHON]: List comprehension example \n","    sCostFunctionName = \" \".join(sCostFunctionNameParts)                             # [PYTHON]: Joining string in a list with the space between them\n","    \n","    \n","    plt.plot(oProcessLog.history['loss'])\n","    plt.plot(oProcessLog.history['val_loss'])\n","    plt.title('CNN ' + sCostFunctionName + \" Error\")\n","    plt.ylabel('Error')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()"],"metadata":{"id":"2vwXe5nBfUtP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference\n","Recalling samples to predict their class (i.e. classify).\n"],"metadata":{"id":"WxBn3-bHgblc"}},{"cell_type":"code","source":["nPredictedProbabilities = oNN.predict(oVSData)\n","nPredictedClassLabels  = np.argmax(nPredictedProbabilities, axis=1)\n","\n","for nIndex, nProbs in enumerate(nPredictedProbabilities):\n","  if nIndex < 5:\n","    print(\"#%.2d Predicted:%d (Probabilities:%s) Actual:%d\" % (nIndex+1, nPredictedClassLabels[nIndex], nProbs, nTargetClassLabels[nIndex])) # [PYTHON] Format string example\n","    if nIndex == 0:\n","      print(\"Sum of all output neuron activations:%.3f\" % np.sum(nProbs))\n"],"metadata":{"id":"XkLjdDwGgh6d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"B2aLiFfZgi7U"}},{"cell_type":"code","source":["from mllib.evaluation import CEvaluator\n","from mllib.visualization import CPlotConfusionMatrix\n","\n","# We create an evaluator object that will produce several metrics\n","oEvaluator = CEvaluator(nTargetClassLabels, nPredictedClassLabels)\n","\n","oEvaluator.PrintConfusionMatrix()\n","print(\"Per Class Recall (Accuracy)  :\", oEvaluator.Recall)\n","print(\"Per Class Precision          :\", oEvaluator.Precision)\n","print(\"Average Accuracy: %.4f\" % oEvaluator.AverageRecall)\n","print(\"Average F1 Score: %.4f\" % oEvaluator.AverageF1Score)\n","      \n","oConfusionMatrixPlot = CPlotConfusionMatrix(oEvaluator.ConfusionMatrix)\n","oConfusionMatrixPlot.Show()      \n"],"metadata":{"id":"UUPSe4dXgbx7"},"execution_count":null,"outputs":[]}]}