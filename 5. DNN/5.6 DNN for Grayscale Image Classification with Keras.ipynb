{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.6 DNN for Grayscale Image Classification with Keras.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuY/QdS4hai0+lalgOYF8s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 5.6 Training a Deep Neural Network for classification of grayscale images of handwritten digits\n","This examples illustrates two DNN models in Tensorflow/Keras, trained to classify handwritten digits from their grayscale images. It uses the well-known MNIST dataset. The second and more powerfull DNN model has  **Normalization Layers** that are helpful for the stability of the learning process."],"metadata":{"id":"DojV2IqZcaom"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0m8s-KccaJp"},"outputs":[],"source":["# Mount GDrive, change directory and check contents of folder.\n","\n","import os\n","from google.colab import drive\n","from google.colab import files\n","\n","PROJECT_FOLDER = \"/content/gdrive/My Drive/Colab Notebooks/CS345_SP22/5. DNN\"\n","\n","drive.mount('/content/gdrive/')\n","os.chdir(PROJECT_FOLDER)\n","print(\"Current dir: \", os.getcwd())"]},{"cell_type":"markdown","source":["# Settings and Basic Package Imports"],"metadata":{"id":"y0TJgTCXbfrZ"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from mllib.utils import RandomSeed\n","\n","# __________ | Settings | __________\n","IS_PLOTING_DATA         = True\n","IS_DEBUGABLE            = False\n","IS_RETRAINING           = True\n","RandomSeed(2022)"],"metadata":{"id":"kIrldDF0bgGt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameters\n","For each training experiment, we define all the model/training hyperparameters inside a Python dictionary."],"metadata":{"id":"5z0Jm3SFxJWv"}},{"cell_type":"code","source":["CONFIG_SHALLOW = {\n","            \"ModelName\": \"MNIST1_SHALLOW\"  \n","           ,\"DNN.InputFeatures\": 28*28\n","           ,\"DNN.LayerNeurons\": [512,10]\n","           ,\"DNN.Classes\": 10\n","           ,\"Training.MaxEpoch\": 10\n","           ,\"Training.BatchSize\": 512\n","           ,\"Training.LearningRate\": 0.2\n","          }"],"metadata":{"id":"-fGhVtyRneUP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We choose the hyperparameter set for the current model training experiment"],"metadata":{"id":"5QwJ_PBpbwOP"}},{"cell_type":"code","source":["CONFIG = CONFIG_SHALLOW"],"metadata":{"id":"YnqkfSVqbuPa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MNIST\n","This [MNIST dataset](http://yann.lecun.com/exdb/mnist/) dataset, that dates back to 1998, has become a standard toy dataset to understand the image classification task. It contains 70000 grayscale images of 28x28 dimensions for the handwritten digits 0,1,..9. \n","It is already splitted into a training set of 60000 images, while the rest 10000 are used to validate the model\n","\n","# Dataset loading and previewing\n","We are reusing an existing dataset in Tensorflow format. We load the data and extract them as numpy arrays to view some images, and later use the target class labels for evaluation."],"metadata":{"id":"Cc5voM78xgaC"}},{"cell_type":"code","source":["import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","\n","(oTSData, oVSData), oDataSetInfo = tfds.load(\n","    'mnist',\n","    split=['train', 'test'],\n","    shuffle_files=True,\n","    as_supervised=True,\n","    with_info=True,\n",")\n","  \n","# Takes one minibatch out of the dataset. Here the size of the minibatch is the total count of samples\n","for tImages, tLabels in oVSData.batch(oDataSetInfo.splits['test'].num_examples).take(1):\n","    nImages            = tImages.numpy()\n","    nTargetClassLabels = tLabels.numpy()  \n","\n","print(\"VS image features tensor shape:\" , nImages.shape)\n","print(\"VS image targets vector shape :\", nTargetClassLabels.shape)\n","\n","if IS_PLOTING_DATA:\n","    for nIndex, nSample in enumerate(nImages):\n","      nLabel = nTargetClassLabels[nIndex]\n","      if (nIndex >= 0 and nIndex <= 20):\n","           \n","        if nIndex == 0:\n","            print(\"Image sample shape            :\", nSample.shape)\n","        nImage =  nSample.astype(np.uint8) \n","        plt.imshow(nImage[:,:,0], cmap=\"gray\") #https://matplotlib.org/stable/tutorials/colors/colormaps.html\n","        #plt.imshow(nImage[4:22, 0:15, :], cmap=\"gray\") #https://matplotlib.org/stable/tutorials/colors/colormaps.html\n","        plt.title(\"Digit %d\" % nLabel)\n","        plt.show()    "],"metadata":{"id":"GxOxQ9AkxYvu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tensorflow/Keras data feeding pipelines\n","We are going to create a pipeline that will feed our training process with data. There is a method used with `map()` that is called for each sample to normalize the value, reshape its features shape and create one-hot encodings for its label. The pipeline uses\n","* `cache`: To cache the data in memory\n","* `shuffle`: To shuffly the samples at each step\n","* `batch`: To create mini-batches of samples\n","* `prefetch`: To use multi-threading for loading the samples into the learning process."],"metadata":{"id":"F3SX-nT0cKTo"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------------\n","def NormalizeAndReshapeImage(p_tImage, p_tLabel):\n","    # Normalizes color component values from `uint8` to `float32`.\n","    tNormalizedImage = tf.cast(p_tImage, tf.float32) / 255.\n","    # Reshapes the 3D tensor of the image (28x28x1) into a 782-dimensional vector\n","    tNormalizedImage = tf.reshape(tNormalizedImage, [CONFIG[\"DNN.InputFeatures\"]])\n","    # Target class labels into one-hot encoding\n","    tTargetOneHot = tf.one_hot(p_tLabel, CONFIG[\"DNN.Classes\"])\n","    \n","    return tNormalizedImage, tTargetOneHot\n","# -----------------------------------------------------------------------------------\n","\n","nBatchSize = CONFIG[\"Training.BatchSize\"]\n","\n","# Training data feed pipeline\n","oTSData = oTSData.map(NormalizeAndReshapeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","oTSData = oTSData.cache()\n","oTSData = oTSData.shuffle(oDataSetInfo.splits['train'].num_examples)\n","oTSData = oTSData.batch(nBatchSize)\n","oTSData = oTSData.prefetch(tf.data.AUTOTUNE)\n","print(\"Training data feed object:\", oTSData)\n","\n","# Validation data feed pipeline\n","oVSData = oVSData.map(NormalizeAndReshapeImage, num_parallel_calls=tf.data.AUTOTUNE)\n","oVSData = oVSData.cache()\n","oVSData = oVSData.batch(oDataSetInfo.splits['test'].num_examples)\n","oVSData = oVSData.prefetch(tf.data.AUTOTUNE)\n","print(\"Validation data feed object:\", oTSData)\n"],"metadata":{"id":"0NK7VS2ocKm4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Deep Neural Network Class\n","We declare the class for a **Fully Connected Deep Neural Network (FC-DNN)** that has a variable depth of hidden layers. "],"metadata":{"id":"rBjC2F3Blqs4"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from tensorflow.keras.layers import Activation, Softmax\\\n","\n","# =========================================================================================================================\n","class CDNNWithNormalization(keras.Model):\n","    # --------------------------------------------------------------------------------------\n","    def __init__(self, p_oConfig):\n","        super(CDNNWithNormalization, self).__init__(p_oConfig)\n","        # ..................... Object Attributes ...........................\n","        self.Config = p_oConfig\n","        \n","        self.ClassCount   = self.Config[\"DNN.LayerNeurons\"][-1]\n","        self.LayerNeurons = self.Config[\"DNN.LayerNeurons\"][:-1]\n","        self.HiddenLayers = [None]*len(self.LayerNeurons)\n","        self.NormalizationLayers = [None]*len(self.LayerNeurons)\n","        self.OutputLayer  = None\n","        self.SoftmaxActivation = None\n","        self.Input        = None\n","        # ...................................................................\n","        \n","        if \"DNN.ActivationFunction\" not in self.Config:\n","            self.Config[\"DNN.ActivationFunction\"] = \"relu\"\n","                    \n","        self.Create()\n","        \n","    # --------------------------------------------------------------------------------------\n","    def Create(self):\n","        for nIndex, nLayerNeuronCount in enumerate(self.LayerNeurons):\n","            self.HiddenLayers[nIndex] = Dense(nLayerNeuronCount, activation=self.Config[\"DNN.ActivationFunction\"], use_bias=True)\n","            self.NormalizationLayers[nIndex] = BatchNormalization()\n","            \n","        self.OutputLayer = Dense(self.ClassCount, use_bias=True)\n","        self.SoftmaxActivation = Softmax() \n","    # --------------------------------------------------------------------------------------\n","    def call(self, p_tInput):\n","        self.Input = p_tInput\n","        \n","        # Feed forward to the next layer\n","        tA = p_tInput\n","        for nIndex, oHiddenLayer in enumerate(self.HiddenLayers):\n","            oNormalizationLayer = self.NormalizationLayers[nIndex]\n","            tA = oHiddenLayer(tA)\n","            tA = oNormalizationLayer(tA)\n","\n","        tA = self.OutputLayer(tA)\n","        # Using the Softmax activation function for the neurons of the output layer \n","        tA = self.SoftmaxActivation(tA)\n","        \n","        return tA    \n","    # --------------------------------------------------------------------------------------\n","# ========================================================================================================================="],"metadata":{"id":"v73nWhSOdLt3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create the Neural Network model and training algorithm objects\n"],"metadata":{"id":"DhT1bvZudWDr"}},{"cell_type":"code","source":["# __________ // Create the Machine Learning model and training algorithm objects \\\\ __________\n","from DNN import CDNNBasic, CDNNWithNormalization\n","\n","oNN = CDNNBasic(CONFIG)\n","\n","nInitialLearningRate    = CONFIG[\"Training.LearningRate\"]\n","\n","oCostFunction   = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","oOptimizer      = tf.keras.optimizers.SGD(learning_rate=nInitialLearningRate)"],"metadata":{"id":"Lw53Davlln-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning Rate Scheduling\n"],"metadata":{"id":"GERRu3a16L5m"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------------\n","def LRSchedule(epoch, lr):\n","    if epoch == 5:\n","        nNewLR = lr * 0.5\n","        print(\"Setting LR to %.5f\" % nNewLR)\n","        return nNewLR\n","    else:\n","        return lr\n","# -----------------------------------------------------------------------------------    \n","    \n","oLearningRateSchedule = tf.keras.callbacks.LearningRateScheduler(LRSchedule)   "],"metadata":{"id":"Is5FyJW36MPX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Process"],"metadata":{"id":"kzI7KKYznfBi"}},{"cell_type":"code","source":["sModelFolderName = CONFIG[\"ModelName\"]\n","        \n","if (not os.path.isdir(sModelFolderName)) or IS_RETRAINING:\n","    oNN.compile(loss=oCostFunction, optimizer=oOptimizer, metrics=[\"accuracy\"])\n","\n","    if IS_DEBUGABLE:\n","        oNN.run_eagerly = True\n","        \n","    oProcessLog = oNN.fit(  oTSData, batch_size=nBatchSize\n","                            ,epochs=CONFIG[\"Training.MaxEpoch\"]\n","                            ,validation_data=oVSData\n","                            ,callbacks=[oLearningRateSchedule] \n","                          )\n","    oNN.summary()          \n","    oNN.save(sModelFolderName)      \n","else:\n","    # The model is trained and its state is saved (all the trainable parameters are saved). We load the model to recall the samples \n","    oNN = keras.models.load_model(sModelFolderName)\n","    oProcessLog = None\n","    oNN.summary()    "],"metadata":{"id":"3Pqd9bgmcdMx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learning Process Overview"],"metadata":{"id":"HdqAw2xpfXz0"}},{"cell_type":"code","source":["if oProcessLog is not None: # [PYTHON] Checks that object reference is not Null\n","    # list all data in history\n","    print(\"Keys of Keras training process log:\", oProcessLog.history.keys())\n","    \n","    # Plot the accuracy during the training epochs\n","    plt.plot(oProcessLog.history['accuracy'])\n","    plt.plot(oProcessLog.history['val_accuracy'])\n","    plt.title('MLP Accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","    \n","    # Plot the error during the training epochs\n","    sCostFunctionNameParts = oCostFunction.name.split(\"_\")                           # [PYTHON]: Splitting string into an array of strings\n","    sCostFunctionNameParts = [x.capitalize() + \" \" for x in sCostFunctionNameParts]  # [PYTHON]: List comprehension example \n","    sCostFunctionName = \" \".join(sCostFunctionNameParts)                             # [PYTHON]: Joining string in a list with the space between them\n","    \n","    \n","    plt.plot(oProcessLog.history['loss'])\n","    plt.plot(oProcessLog.history['val_loss'])\n","    plt.title('MLP ' + sCostFunctionName + \" Error\")\n","    plt.ylabel('Error')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()"],"metadata":{"id":"2vwXe5nBfUtP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference\n","Recalling samples to predict their class (i.e. classify).\n"],"metadata":{"id":"WxBn3-bHgblc"}},{"cell_type":"code","source":["nPredictedProbabilities = oNN.predict(oVSData)\n","nPredictedClassLabels  = np.argmax(nPredictedProbabilities, axis=1)\n","\n","for nIndex, nProbs in enumerate(nPredictedProbabilities):\n","  if nIndex < 5:\n","    print(\"#%.2d Predicted:%d (Probabilities:%s) Actual:%d\" % (nIndex+1, nPredictedClassLabels[nIndex], nProbs, nTargetClassLabels[nIndex])) # [PYTHON] Format string example\n","    if nIndex == 0:\n","      print(\"Sum of all output neuron activations:%.3f\" % np.sum(nProbs))\n"],"metadata":{"id":"XkLjdDwGgh6d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"B2aLiFfZgi7U"}},{"cell_type":"code","source":["from mllib.evaluation import CEvaluator\n","from mllib.visualization import CPlotConfusionMatrix\n","\n","# We create an evaluator object that will produce several metrics\n","oEvaluator = CEvaluator(nTargetClassLabels, nPredictedClassLabels)\n","\n","oEvaluator.PrintConfusionMatrix()\n","print(\"Per Class Recall (Accuracy)  :\", oEvaluator.Recall)\n","print(\"Per Class Precision          :\", oEvaluator.Precision)\n","print(\"Average Accuracy: %.4f\" % oEvaluator.AverageRecall)\n","print(\"Average F1 Score: %.4f\" % oEvaluator.AverageF1Score)\n","      \n","oConfusionMatrixPlot = CPlotConfusionMatrix(oEvaluator.ConfusionMatrix)\n","oConfusionMatrixPlot.Show()      \n"],"metadata":{"id":"UUPSe4dXgbx7"},"execution_count":null,"outputs":[]}]}